{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ac1d2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sahi.predict import get_sliced_prediction\n",
    "from sahi import AutoDetectionModel\n",
    "from sahi.predict import get_prediction\n",
    "from sahi import AutoDetectionModel\n",
    "from sahi.predict import predict\n",
    "from sahi import AutoDetectionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fd32de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mbest.pt\u001b[0m*  \u001b[01;32mbest_fold0.pt\u001b[0m*  \u001b[01;32mlast.pt\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "ls '///mnt/c/Personal/Competitions/Zindi/Wadhwani AI/runs/yolov5l6_exp003/fold 0/fold0/weights'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a257165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"yolov5\"\n",
    "model_path = '///mnt/c/Personal/Competitions/Zindi/Wadhwani AI/runs/yolov5l6_exp003/fold 0/fold0/weights/best.pt'\n",
    "model_device = \"cuda:0\" # or 'cuda:0'\n",
    "model_confidence_threshold = 0.4\n",
    "\n",
    "slice_height = 256\n",
    "slice_width = 256\n",
    "overlap_height_ratio = 0.2\n",
    "overlap_width_ratio = 0.2\n",
    "source_image_dir = '///mnt/c/Personal/Competitions/Zindi/Wadhwani AI/data/test_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd8d04fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2803 listed files in folder: test_images/\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yolov5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_confidence_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_confidence_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource_image_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mslice_height\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_height\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mslice_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverlap_height_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverlap_height_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverlap_width_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverlap_width_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/sahi/predict.py:473\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(detection_model, model_type, model_path, model_config_path, model_confidence_threshold, model_device, model_category_mapping, model_category_remapping, source, no_standard_prediction, no_sliced_prediction, image_size, slice_height, slice_width, overlap_height_ratio, overlap_width_ratio, postprocess_type, postprocess_match_metric, postprocess_match_threshold, postprocess_class_agnostic, novisual, view_video, frame_skip_interval, export_pickle, export_crop, dataset_json_path, project, name, visual_bbox_thickness, visual_text_size, visual_text_thickness, visual_export_format, verbose, return_dict, force_postprocess_type)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m detection_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     detection_model \u001b[38;5;241m=\u001b[39m AutoDetectionModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    463\u001b[0m         model_type\u001b[38;5;241m=\u001b[39mmodel_type,\n\u001b[1;32m    464\u001b[0m         model_path\u001b[38;5;241m=\u001b[39mmodel_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    471\u001b[0m         image_size\u001b[38;5;241m=\u001b[39mimage_size,\n\u001b[1;32m    472\u001b[0m     )\n\u001b[0;32m--> 473\u001b[0m     \u001b[43mdetection_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m time_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m time_start\n\u001b[1;32m    475\u001b[0m durations_in_seconds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_load\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m time_end\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/sahi/models/yolov5.py:26\u001b[0m, in \u001b[0;36mYolov5DetectionModel.load_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    Detection model is initialized and set to self.model.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myolov5\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m         model \u001b[38;5;241m=\u001b[39m yolov5\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_path, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yolov5'"
     ]
    }
   ],
   "source": [
    "predict(\n",
    "    model_type=model_type,\n",
    "    model_path=model_path,\n",
    "    model_device=model_device,\n",
    "    model_confidence_threshold=model_confidence_threshold,\n",
    "    source=source_image_dir,\n",
    "    slice_height=slice_height,\n",
    "    slice_width=slice_width,\n",
    "    overlap_height_ratio=overlap_height_ratio,\n",
    "    overlap_width_ratio=overlap_width_ratio,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15396a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f985d11f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a88c2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0debfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257c2a38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7b157a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92217977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca83504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae4fa0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c312fdee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c83b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
