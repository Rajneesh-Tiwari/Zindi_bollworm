{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46537662",
   "metadata": {},
   "source": [
    "### Regression notebook for Wadhwani AI competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d241113",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T04:46:40.770422Z",
     "iopub.status.busy": "2022-10-21T04:46:40.768650Z",
     "iopub.status.idle": "2022-10-21T04:46:46.027848Z",
     "shell.execute_reply": "2022-10-21T04:46:46.026647Z"
    },
    "id": "_b9cHesklRKW",
    "outputId": "0251b11b-0475-4dbb-dd52-7b75ec6d27e9",
    "papermill": {
     "duration": 5.275668,
     "end_time": "2022-10-21T04:46:46.030655",
     "exception": false,
     "start_time": "2022-10-21T04:46:40.754987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "from glob import glob\n",
    "from sklearn.model_selection import GroupKFold, KFold, StratifiedKFold\n",
    "import warnings\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import sys\n",
    "from requests import get\n",
    "import multiprocessing\n",
    "import joblib\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "# from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "import timm\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2,torchvision\n",
    "from ipyexperiments.ipyexperiments import IPyExperimentsPytorch\n",
    "from timm.optim.optim_factory import create_optimizer_v2\n",
    "from timm import utils\n",
    "from fastprogress.fastprogress import format_time\n",
    "from fastai.vision.all import *\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "import yolov5\n",
    "class CFG:\n",
    "    seed = 46\n",
    "    n_splits = 5\n",
    "    SZ = 1280\n",
    "    debug = False\n",
    "    BS = 8\n",
    "    EP = 10\n",
    "    MODEL = 'tf_efficientnet_b0_ns'\n",
    "    LR = 5e-03\n",
    "    WD = 1e-08\n",
    "\n",
    "random.seed(CFG.seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(CFG.seed)\n",
    "np.random.seed(CFG.seed)\n",
    "plt.rcParams[\"font.size\"] = 13\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f1fe7694",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T04:46:46.053836Z",
     "iopub.status.busy": "2022-10-21T04:46:46.053171Z",
     "iopub.status.idle": "2022-10-21T04:46:46.061921Z",
     "shell.execute_reply": "2022-10-21T04:46:46.060953Z"
    },
    "papermill": {
     "duration": 0.022786,
     "end_time": "2022-10-21T04:46:46.064147",
     "exception": false,
     "start_time": "2022-10-21T04:46:46.041361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae2a4371",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T04:46:46.086954Z",
     "iopub.status.busy": "2022-10-21T04:46:46.086674Z",
     "iopub.status.idle": "2022-10-21T04:46:46.149851Z",
     "shell.execute_reply": "2022-10-21T04:46:46.148778Z"
    },
    "id": "PD4IsNvglQYA",
    "papermill": {
     "duration": 0.077084,
     "end_time": "2022-10-21T04:46:46.152797",
     "exception": false,
     "start_time": "2022-10-21T04:46:46.075713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Personal/Competitions/Zindi/Wadhwani AI/runs/Regression/NB_EXP_V0_009_Regression\n",
      "tf_efficientnet_b0_ns_1280_bs8_ep10_lr0.005_wd1e08\n"
     ]
    }
   ],
   "source": [
    "DIR = '///mnt/c/Personal/Competitions/Zindi/Wadhwani AI/data/'\n",
    "IMG_PATH = '///mnt/c/Personal/Competitions/Zindi/Wadhwani AI/data/images'\n",
    "submit = pd.read_csv(os.path.join(DIR,'SampleSubmission.csv'))\n",
    "train = pd.read_csv(os.path.join(DIR,'Train.csv'))\n",
    "test_df = pd.read_csv(os.path.join(DIR,'Test.csv'))\n",
    "\n",
    "VERSION = \"NB_EXP_V0_009_Regression\"\n",
    "MODEL_FOLDER = Path(f\"///mnt/c/Personal/Competitions/Zindi/Wadhwani AI/runs/Regression/{VERSION}/\")\n",
    "os.makedirs(MODEL_FOLDER,exist_ok=True)\n",
    "KERNEL_TYPE = f\"{CFG.MODEL}_{CFG.SZ}_bs{CFG.BS}_ep{CFG.EP}_lr{str(CFG.LR).replace('-','')}_wd{str(CFG.WD).replace('-','')}\"\n",
    "\n",
    "print(MODEL_FOLDER)\n",
    "print(KERNEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c81063fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_dataset():\n",
    "    train_new_pbw = pd.DataFrame()\n",
    "    train_new_pbw['image_id_worm']= train['image_id_worm'].unique()\n",
    "    train_new_pbw = pd.merge(train_new_pbw,train[train['worm_type']=='pbw'].reset_index(drop=True),on='image_id_worm',how='left')\n",
    "    train_new_pbw['worm_type'] = 'pbw'\n",
    "    train_new_pbw.fillna(0,inplace=True)\n",
    "    \n",
    "    train_new_abw = pd.DataFrame()\n",
    "    train_new_abw['image_id_worm']= train['image_id_worm'].unique()\n",
    "    train_new_abw = pd.merge(train_new_abw,train[train['worm_type']=='abw'].reset_index(drop=True),on='image_id_worm',how='left')\n",
    "    train_new_abw['worm_type'] = 'abw'\n",
    "    train_new_abw.fillna(0,inplace=True)\n",
    "    \n",
    "    train_out = pd.concat([train_new_pbw,train_new_abw],0).reset_index(drop=True)\n",
    "    \n",
    "    assert len(train_out) == train['image_id_worm'].nunique()*2\n",
    "    train_out = pd.pivot(train_out,'image_id_worm','worm_type','number_of_worms').reset_index()\n",
    "    train_out[['abw','pbw']] = train_out[['abw','pbw']].astype(int)\n",
    "    \n",
    "    labels = [f'{i}' for i in range(10)]\n",
    "    train_out['abw_bins'] = pd.cut(train_out['abw'],10,labels=labels)\n",
    "    train_out['pbw_bins'] = pd.cut(train_out['pbw'],10,labels=labels)\n",
    "    train_out['consol_bins'] = train_out['abw_bins'].astype(str)+'_'+train_out['pbw_bins'].astype(str)\n",
    "    \n",
    "#     train_out = train_out[['image_id_worm','abw','pbw','abw_bins','pbw_bins','consol_bins']]\n",
    "    return train_out\n",
    "\n",
    "train_new = make_train_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a9ddfc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>worm_type</th>\n",
       "      <th>image_id_worm</th>\n",
       "      <th>abw</th>\n",
       "      <th>pbw</th>\n",
       "      <th>abw_bins</th>\n",
       "      <th>pbw_bins</th>\n",
       "      <th>consol_bins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0002ea6f15c7fa6f4c221783.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "worm_type                    image_id_worm  abw  pbw abw_bins pbw_bins  \\\n",
       "0          id_0002ea6f15c7fa6f4c221783.jpg    0   51        0        0   \n",
       "\n",
       "worm_type consol_bins  \n",
       "0                 0_0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11cfd590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9737, 6)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd909d43",
   "metadata": {
    "papermill": {
     "duration": 0.010524,
     "end_time": "2022-10-21T04:46:47.308030",
     "exception": false,
     "start_time": "2022-10-21T04:46:47.297506",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Get kfolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3fb3ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = []\n",
    "val_files = []\n",
    "fold = []\n",
    "\n",
    "for folds in [0,1,2,3,4]:\n",
    "    files = list(pd.read_csv(f'///mnt/c/Personal/Competitions/Zindi/Wadhwani AI/data/splits/fold{folds}.txt',header=None)[0].apply(lambda x:x.split(\"/\")[-1]))\n",
    "    fold.append([folds]*len(files))\n",
    "    train_files.append(files)\n",
    "\n",
    "train_files= ([item for sublist in train_files for item in sublist])\n",
    "fold= ([item for sublist in fold for item in sublist])\n",
    "fold_dict = dict(zip(train_files,fold))\n",
    "train_new['fold'] = train_new['image_id_worm'].map(fold_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d68546c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7079, 7)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new = train_new.loc[~train_new['fold'].isna()].reset_index(drop=True)\n",
    "train_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87fc7e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mskf = StratifiedKFold(n_splits=CFG.n_splits, shuffle=True, random_state=42)\n",
    "# fold_ids = []\n",
    "# train_new['fold'] = 0\n",
    "\n",
    "# for train_index, test_index in mskf.split(train_new, train_new['consol_bins']):\n",
    "#     fold_ids.append(test_index)\n",
    "    \n",
    "# for fld in range(CFG.n_splits):\n",
    "#     valIx = fold_ids[fld]\n",
    "#     train_new.loc[valIx,'fold']=fld "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3ff7d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    1418\n",
       "4.0    1417\n",
       "3.0    1417\n",
       "1.0    1416\n",
       "2.0    1411\n",
       "Name: fold, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new['fold'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6721b71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new['fold'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5e26d3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id_worm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_00332970f80fa9a47a39516d.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     image_id_worm\n",
       "0  id_00332970f80fa9a47a39516d.jpg"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfb2b79",
   "metadata": {
    "papermill": {
     "duration": 0.011456,
     "end_time": "2022-10-21T04:46:50.483973",
     "exception": false,
     "start_time": "2022-10-21T04:46:50.472517",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c73ecef4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T04:46:51.308402Z",
     "iopub.status.busy": "2022-10-21T04:46:51.308008Z",
     "iopub.status.idle": "2022-10-21T04:46:51.318874Z",
     "shell.execute_reply": "2022-10-21T04:46:51.317960Z"
    },
    "papermill": {
     "duration": 0.028413,
     "end_time": "2022-10-21T04:46:51.321386",
     "exception": false,
     "start_time": "2022-10-21T04:46:51.292973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WadhwaniDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 df=train_new,\n",
    "                 mode='train',\n",
    "                augs = None):\n",
    "        \n",
    "        self.augs = augs\n",
    "        self.df = df\n",
    "        self.mode  = mode\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, ix):\n",
    "        image_id = self.df.loc[ix,'image_id_worm']\n",
    "        img_path = f'{IMG_PATH}/{image_id}'\n",
    "        \n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img = np.array(img)\n",
    "        \n",
    "        if self.augs is not None:\n",
    "            img = self.augs(image=img)['image']\n",
    "    \n",
    "        if self.mode == 'test':\n",
    "            return img\n",
    "        \n",
    "        label = torch.tensor(self.df[['abw','pbw']].loc[ix]).float()\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05285e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOv5TorchBackend(nn.Module):\n",
    "    # YOLOv5 MultiBackend class for python inference on various backends\n",
    "    def __init__(self, weights='yolov5s.pt', device=torch.device('cpu'), data=None, fp16=False, fuse=True):\n",
    "        # Usage:\n",
    "        #   PyTorch:              weights = *.pt\n",
    "        \n",
    "        self.pt = True\n",
    "        \n",
    "        from yolov5.models.experimental import (attempt_download, attempt_load)\n",
    "\n",
    "        super().__init__()\n",
    "        w = str(weights[0] if isinstance(weights, list) else weights)\n",
    "        w = attempt_download(w)  # download if not local\n",
    "        fp16 &= True\n",
    "        stride = 32  # default stride\n",
    "        cuda = torch.cuda.is_available() and device.type != 'cpu'  # use CUDA\n",
    "\n",
    "        model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)\n",
    "        stride = max(int(model.stride.max()), 32)  # model stride\n",
    "        names = model.module.names if hasattr(model, 'module') else model.names  # get class names\n",
    "        model.half() if fp16 else model.float()\n",
    "        self.model = model\n",
    "\n",
    "        self.__dict__.update(locals())  # assign all variables to self\n",
    "\n",
    "    def forward(self, im, augment=False, visualize=False):\n",
    "        # YOLOv5 MultiBackend inference\n",
    "        b, ch, h, w = im.shape  # batch, channel, height, width\n",
    "        if self.fp16 and im.dtype != torch.float16:\n",
    "            im = im.half()  # to FP16\n",
    "\n",
    "        y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n",
    "\n",
    "        if isinstance(y, (list, tuple)):\n",
    "            return self.from_numpy(y[0]) if len(y) == 1 else [self.from_numpy(x) for x in y]\n",
    "        else:\n",
    "            return self.from_numpy(y)\n",
    "\n",
    "    def from_numpy(self, x):\n",
    "        return torch.from_numpy(x).to(self.device) if isinstance(x, np.ndarray) else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf7f7228",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureMapsAverager(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.f = -1\n",
    "        self.i = True\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        result = self.pool(x)\n",
    "        result = result.flatten(1)\n",
    "        \n",
    "        return result\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a46858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WadhwaniYoloFeatDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 df=train_new,\n",
    "                 mode='train',\n",
    "                 yolo = None,\n",
    "                augs = None):\n",
    "        \n",
    "        self.augs = augs\n",
    "        self.df = df\n",
    "        self.mode  = mode\n",
    "        self.yolo = yolo\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, ix):\n",
    "        image_id = self.df.loc[ix,'image_id_worm']\n",
    "        img_path = f'{IMG_PATH}/{image_id}'\n",
    "        \n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img = np.array(img)\n",
    "        \n",
    "        if self.augs is not None:\n",
    "            img = self.augs(image=img)['image']\n",
    "            \n",
    "        yFeats = self.yolo(img.unsqueeze(0))\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            return img,yFeats\n",
    "        \n",
    "        label = torch.tensor(self.df[['abw','pbw']].loc[ix]).float()\n",
    "        return img, yFeats,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "101207aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T04:46:51.351557Z",
     "iopub.status.busy": "2022-10-21T04:46:51.351216Z",
     "iopub.status.idle": "2022-10-21T04:46:51.356377Z",
     "shell.execute_reply": "2022-10-21T04:46:51.355263Z"
    },
    "papermill": {
     "duration": 0.025285,
     "end_time": "2022-10-21T04:46:51.358947",
     "exception": false,
     "start_time": "2022-10-21T04:46:51.333662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def worker_init_fn(worker_id):\n",
    "    \"\"\"\n",
    "    Handles PyTorch x Numpy seeding issues.\n",
    "    Args:\n",
    "        worker_id (int): Id of the worker.\n",
    "    \"\"\"\n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9b59ef",
   "metadata": {},
   "source": [
    "### Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "500ddfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TRAIN_AUG = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.ShiftScaleRotate(rotate_limit=45, border_mode=0, p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1,p=0.5),\n",
    "    A.Blur(p=0.5),\n",
    "#     A.CLAHE(p=0.5),\n",
    "    A.Resize(CFG.SZ,CFG.SZ,p=1),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "VALID_AUG = A.Compose([\n",
    "    A.Resize(CFG.SZ,CFG.SZ,p=1),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "\n",
    "YOLO_AUG = A.Compose([\n",
    "    A.Resize(3072,3072,p=1),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "\n",
    "YOLO_AUG1 = A.Compose([\n",
    "    A.Resize(3584,3584,p=1),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a798ab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo_detection_model = YOLOv5TorchBackend(weights='/mnt/c/Personal/Competitions/Zindi/Wadhwani AI/runs/yolov5l6_exp003/fold 0/fold0/weights/best_fold0.pt', device=torch.device(\"cpu\"))\n",
    "# model = yolo_detection_model.model\n",
    "# model.model[-1] = FeatureMapsAverager()\n",
    "# model.eval()\n",
    "# a,b,c = next(iter(WadhwaniYoloFeatDataset(augs=TRAIN_AUG,yolo=model)))\n",
    "# a.shape,b.shape,c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bf59ae",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4410391e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataset_show = WadhwaniDataset(train_new, augs=TRAIN_AUG, mode='train')\n",
    "# loader_show = torch.utils.data.DataLoader(dataset_show, batch_size=6)\n",
    "# img,target = next(iter(loader_show))\n",
    "\n",
    "# grid = torchvision.utils.make_grid(img, normalize=True, padding=2)\n",
    "# grid = grid.permute(1, 2, 0)\n",
    "# show_image(grid, figsize=(15,8))#, title=[labels_class_map_rev[x] for x in target.numpy()]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083f9823",
   "metadata": {
    "papermill": {
     "duration": 0.012058,
     "end_time": "2022-10-21T04:46:51.383502",
     "exception": false,
     "start_time": "2022-10-21T04:46:51.371444",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "20034eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_wadhwani_regression_model(model_name, pretrained=True, **kwargs):\n",
    "#     model = timm.create_model(model_name, pretrained=pretrained, **kwargs)\n",
    "#     model = nn.Sequential(model, nn.Dropout(0.15), nn.Linear(model.num_classes, 2),nn.ReLU())\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b33a795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = timm.create_model(CFG.MODEL, pretrained=True,num_classes=0)\n",
    "# m(torch.randn(1,3,124,124)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "26e5a969",
   "metadata": {},
   "outputs": [],
   "source": [
    "class get_wadhwani_regression_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(CFG.MODEL, pretrained=True,drop_path_rate=0.15,num_classes=0)\n",
    "        self.linear = nn.Sequential(nn.Linear(1280+1024,2),nn.ReLU())\n",
    "    \n",
    "    def forward(self,img,yf):\n",
    "        _if = self.model(img)\n",
    "#         print(_if.shape,yf.squeeze(1).shape)\n",
    "        _if = torch.cat([_if,yf.squeeze(1)],1)\n",
    "        res = self.linear(_if)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "337b9d6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = timm.create_model(CFG.MODEL, pretrained=True)\n",
    "# model.num_classes\n",
    "# nn.Sequential(model, nn.Dropout(0.15), nn.Linear(model.num_classes, 2),nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d41add6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T04:46:51.748231Z",
     "iopub.status.busy": "2022-10-21T04:46:51.747517Z",
     "iopub.status.idle": "2022-10-21T04:46:51.959456Z",
     "shell.execute_reply": "2022-10-21T04:46:51.958430Z"
    },
    "papermill": {
     "duration": 0.227045,
     "end_time": "2022-10-21T04:46:51.962222",
     "exception": false,
     "start_time": "2022-10-21T04:46:51.735177",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dl = DataLoader(WadhwaniYoloFeatDataset(train_new, augs=TRAIN_AUG, mode='train',yolo=model),\n",
    "#                           batch_size=2,\n",
    "#                           shuffle=True,\n",
    "#                           num_workers=8,\n",
    "#                           drop_last=True,\n",
    "#                         worker_init_fn=worker_init_fn)\n",
    "\n",
    "# a,b,c = next(iter(dl))\n",
    "# a.shape,b.shape,c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e6a3e892",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T04:46:51.987500Z",
     "iopub.status.busy": "2022-10-21T04:46:51.987165Z",
     "iopub.status.idle": "2022-10-21T04:46:58.618975Z",
     "shell.execute_reply": "2022-10-21T04:46:58.616805Z"
    },
    "papermill": {
     "duration": 6.647161,
     "end_time": "2022-10-21T04:46:58.621465",
     "exception": false,
     "start_time": "2022-10-21T04:46:51.974304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# m = get_wadhwani_regression_model()\n",
    "# out = m(a,b)\n",
    "# print(out, out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c5722ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.L1Loss()(out,c).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fff2ad",
   "metadata": {
    "papermill": {
     "duration": 0.013027,
     "end_time": "2022-10-21T04:46:58.648053",
     "exception": false,
     "start_time": "2022-10-21T04:46:58.635026",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train & Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8c498a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    loader: Iterable,\n",
    "    loss_fn: Callable,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    lr_scheduler: torch.optim.lr_scheduler._LRScheduler = None,\n",
    "    mixup_fn: Callable = None,\n",
    "    grad_scaler: torch.cuda.amp.GradScaler = None,\n",
    "    mbar: master_bar = None,\n",
    "):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    losses_m = utils.AverageMeter()\n",
    "\n",
    "    pbar = progress_bar(loader, parent=mbar, leave=False)\n",
    "    pbar.update(0)\n",
    "\n",
    "    for batch_idx, (input,yf, target) in enumerate(loader):\n",
    "        input, yf, target = input.cuda(), yf.cuda(),target.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast(enabled=True):\n",
    "            output = model(input,yf)\n",
    "            loss = loss_fn(output, target)\n",
    "            \n",
    "        losses_m.update(loss.item(), input.size(0))\n",
    "\n",
    "        grad_scaler.scale(loss).backward()\n",
    "        grad_scaler.step(optimizer)\n",
    "        grad_scaler.update()\n",
    "\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        pbar.update(batch_idx + 1)\n",
    "        pbar.comment = f\"{losses_m.avg:.4f}\"\n",
    "\n",
    "    pbar.on_iter_end()\n",
    "    return OrderedDict([(\"loss\", losses_m.avg)])\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def validate(model: nn.Module, loader: Iterable, loss_fn: Callable, mbar: master_bar):\n",
    "    model.eval()\n",
    "\n",
    "    l1_loss_m = utils.AverageMeter()\n",
    "    losses_m = utils.AverageMeter()\n",
    "\n",
    "    pbar = progress_bar(loader, parent=mbar, leave=False)\n",
    "    pbar.update(0)\n",
    "\n",
    "    for batch_idx, (input, yf,target) in enumerate(loader):\n",
    "        \n",
    "        input, yf, target = input.cuda(), yf.cuda(), target.cuda()\n",
    "        output = torch.round(model(input,yf))\n",
    "\n",
    "        loss = loss_fn(output, target).item()\n",
    "        losses_m.update(loss, input.size(0))\n",
    "\n",
    "        l1_loss = nn.L1Loss()(output, target).item()\n",
    "        l1_loss_m.update(l1_loss, output.size(0))\n",
    "\n",
    "        pbar.update(batch_idx + 1)\n",
    "\n",
    "    pbar.on_iter_end()\n",
    "    return OrderedDict([(\"loss\", losses_m.avg), (\"l1_loss\", l1_loss_m.avg)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa69aca",
   "metadata": {},
   "source": [
    "### save on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3d1e0fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WadhwaniDatasetSimple(Dataset):\n",
    "    def __init__(self,\n",
    "                 df=train_new,\n",
    "                 mode='train',\n",
    "                augs = None):\n",
    "        \n",
    "        self.augs = augs\n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, ix):\n",
    "        image_id = self.df.loc[ix,'image_id_worm']\n",
    "        img_path = f'{IMG_PATH}/{image_id}'\n",
    "        \n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img = np.array(img)\n",
    "        \n",
    "        if self.augs is not None:\n",
    "            img = self.augs(image=img)['image']\n",
    "        \n",
    "        return image_id,img\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d3d8593b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id_worm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_00332970f80fa9a47a39516d.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_0035981bc3ae42eb5b57a317.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_005102f664b820f778291dee.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0066456f5fb2cd858c69ab39.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_007159c1fa015ba6f394deeb.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>id_ffad8f3773a4222f8fe5ba1a.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>id_ffb65e6de900c49d8f2ef95a.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>id_ffbcb27fa549278f47505515.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801</th>\n",
       "      <td>id_ffc0e41e10b0c964d4a02811.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>id_fff8c253115aacded09ad7ed.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2803 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        image_id_worm\n",
       "0     id_00332970f80fa9a47a39516d.jpg\n",
       "1     id_0035981bc3ae42eb5b57a317.jpg\n",
       "2     id_005102f664b820f778291dee.jpg\n",
       "3     id_0066456f5fb2cd858c69ab39.jpg\n",
       "4     id_007159c1fa015ba6f394deeb.jpg\n",
       "...                               ...\n",
       "2798  id_ffad8f3773a4222f8fe5ba1a.jpg\n",
       "2799  id_ffb65e6de900c49d8f2ef95a.jpg\n",
       "2800  id_ffbcb27fa549278f47505515.jpg\n",
       "2801  id_ffc0e41e10b0c964d4a02811.jpg\n",
       "2802  id_fff8c253115aacded09ad7ed.jpg\n",
       "\n",
       "[2803 rows x 1 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fc787d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e648c93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yolo.py:141 -                 fuse() | Fusing layers... \n",
      "Fusing layers... \n",
      "torch_utils.py:293 -           model_info() | Model summary: 281 layers, 12326164 parameters, 0 gradients, 16.3 GFLOPs\n",
      "Model summary: 281 layers, 12326164 parameters, 0 gradients, 16.3 GFLOPs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89fb0711a0a04bd2a3aa60876f819ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2803 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fold in range(1):\n",
    "#     yValFeats = dict()\n",
    "    yTestFeats = dict()\n",
    "\n",
    "    yolo_detection_model = YOLOv5TorchBackend(weights=f'/mnt/c/Personal/Competitions/Zindi/Wadhwani AI/runs/yolov5s6_exp001/fold {fold}/weights/best.pt', device=torch.device(\"cpu\"))\n",
    "    yolomodel = yolo_detection_model.model\n",
    "    yolomodel.model[-1] = FeatureMapsAverager()\n",
    "    yolomodel.cuda()\n",
    "    yolomodel.eval()\n",
    "    \n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    dataset_test = WadhwaniDatasetSimple(test_df.reset_index(drop=True), augs=YOLO_AUG, mode=\"valid\")\n",
    "    \n",
    "    loader_test = torch.utils.data.DataLoader(dataset_test, 1 , num_workers=8, shuffle=False)\n",
    "\n",
    "    for k,(id,img) in tqdm(enumerate(loader_test),total=len(loader_test)):\n",
    "        with torch.no_grad():\n",
    "            yTestFeats[id] = yolomodel(img.cuda())    \n",
    "try:\n",
    "    del yolo_detection_model, yolomodel\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5f06765a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yolo.py:141 -                 fuse() | Fusing layers... \n",
      "Fusing layers... \n",
      "torch_utils.py:293 -           model_info() | Model summary: 281 layers, 12326164 parameters, 0 gradients, 16.3 GFLOPs\n",
      "Model summary: 281 layers, 12326164 parameters, 0 gradients, 16.3 GFLOPs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352f6836a41e45c197d7bc7632eddb25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2803 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fold in range(1):\n",
    "    yTestFeats1 = dict()\n",
    "\n",
    "    yolo_detection_model = YOLOv5TorchBackend(weights=f'/mnt/c/Personal/Competitions/Zindi/Wadhwani AI/runs/yolov5s6_exp002/fold {fold}/weights/best.pt', device=torch.device(\"cpu\"))\n",
    "    yolomodel = yolo_detection_model.model\n",
    "    yolomodel.model[-1] = FeatureMapsAverager()\n",
    "    yolomodel.cuda()\n",
    "    yolomodel.eval()\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    dataset_test = WadhwaniDatasetSimple(test_df.reset_index(drop=True), augs=YOLO_AUG, mode=\"valid\")\n",
    "    loader_test = torch.utils.data.DataLoader(dataset_test, 1 , num_workers=8, shuffle=False)\n",
    "\n",
    "    for k,(id,img) in tqdm(enumerate(loader_test),total=len(loader_test)):\n",
    "        with torch.no_grad():\n",
    "            yTestFeats1[id] = yolomodel(img.cuda())    \n",
    "try:\n",
    "    del yolo_detection_model, yolomodel\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "351e1e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open(f'/mnt/c/Personal/Competitions/Zindi/Wadhwani AI/runs/YOLO_Features/yolov5s6_exp001_test.pickle', 'wb') as handle:\n",
    "    pickle.dump(yTestFeats, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(f'/mnt/c/Personal/Competitions/Zindi/Wadhwani AI/runs/YOLO_Features/yolov5s6_exp002_test.pickle', 'wb') as handle:\n",
    "    pickle.dump(yTestFeats1, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964d06bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0a3fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbb57bf2",
   "metadata": {
    "id": "T0Z5tB5f8obu",
    "papermill": {
     "duration": 0.018419,
     "end_time": "2022-10-21T04:58:56.268413",
     "exception": false,
     "start_time": "2022-10-21T04:58:56.249994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Fin "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 771.032802,
   "end_time": "2022-10-21T04:58:58.627815",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-10-21T04:46:07.595013",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
